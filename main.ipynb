{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.28.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.8)\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\camil\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->openai) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import chainlit as cl\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"what's your name\"\n",
    "        }\n",
    "    ],\n",
    "    temperature =1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty = 0,\n",
    "    presence_penalty = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8HbgfJ7CVb87R2Fm2Uw2YT1axoS3F\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699207137,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I am an AI language model developed by OpenAI and I am called GPT-3. How can I assist you today?\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"completion_tokens\": 26,\n",
      "    \"total_tokens\": 37\n",
      "  }\n",
      "}\n",
      "I am an AI language model developed by OpenAI and I am called GPT-3. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "# print(response.choices[0].message.content)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are a specialized family law attorney\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"Hola, soy de colombia, soy mujer y me quiero divorciar de mi marido\"\n",
    "        }\n",
    "    ],\n",
    "    temperature =0.3,\n",
    "    # max_tokens=256,\n",
    "    # top_p=1,\n",
    "    # frequency_penalty = 0,\n",
    "    # presence_penalty = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, entiendo que estás interesada en divorciarte de tu esposo. Como abogado especializado en derecho de familia, puedo orientarte en este proceso.\n",
      "\n",
      "En primer lugar, es importante que sepas que las leyes de divorcio pueden variar de un país a otro, por lo que te recomendaría que consultes con un abogado local en Colombia para obtener asesoramiento específico sobre tus derechos y opciones legales en tu jurisdicción.\n",
      "\n",
      "Sin embargo, en general, existen diferentes vías legales para llevar a cabo un divorcio. En Colombia, por ejemplo, tienes la opción de presentar una demanda de divorcio ante un juez, conocido como divorcio contencioso. Esto significa que ambas partes no están de acuerdo y necesitarán la intervención de un tribunal para resolver los problemas pendientes, como la división de bienes, la custodia de los hijos y los arreglos de manutención.\n",
      "\n",
      "Por otro lado, también puedes buscar un divorcio de mutuo acuerdo, en el que ambas partes están de acuerdo con los términos y condiciones del divorcio. En este caso, podrían presentar conjuntamente una solicitud de divorcio ante un juez, y si el juez lo aprueba, se emitirá una sentencia de divorcio.\n",
      "\n",
      "Es importante que consultes con un abogado de familia en tu área para guiarte adecuadamente a través de este proceso y asegurarte de que tus derechos sean protegidos en el proceso de divorcio.\n",
      "\n",
      "Recuerda que el divorcio puede ser un proceso emocionalmente difícil, por lo que también es recomendable buscar apoyo emocional durante este tiempo.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktokenNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     -------------------------------------- 42.0/42.0 kB 406.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camil\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-win_amd64.whl (759 kB)\n",
      "   ---------------------------------------- 759.8/759.8 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp310-cp310-win_amd64.whl (269 kB)\n",
      "   --------------------------------------- 269.6/269.6 kB 17.3 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_message(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"\"Returns the number of tokens used by a list of messages\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. using c1100k_ base encoding\")\n",
    "        encoding = tiktoken.get_encoding(\"c1100k_base\")\n",
    "    if model in  {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = 1 #if there's a name, role is omitted\n",
    "    elif \"gpt-3.5-turbo\":\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-0613.\")\n",
    "        return num_tokens_from_message(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "                \n",
    "    elif \"gpt-4\":\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_message(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"num_tokens_from_messages() is not implemented for {model}.\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3 # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0301\n",
      "261 prompt tokens counted by num_tokens_from_messages().\n",
      "252 prompt tokens counted by the OPENAI API. \n",
      "gpt-3.5-turbo-0613\n",
      "255 prompt tokens counted by num_tokens_from_messages().\n"
     ]
    }
   ],
   "source": [
    "example_messages = [\n",
    "    {\"role\": \"user\", \"name\": \"user\", \"content\": \"Hola, necesito ayuda legal. ¿Puede explicarme algunos aspectos clave de la ley colombiana?\"},\n",
    "    {\"role\": \"system\", \"name\": \"system\", \"content\": \"¡Hola! Claro, estaré encantado de ayudarte con la ley colombiana. ¿En qué área específica necesitas información?\"},\n",
    "    {\"role\": \"user\", \"name\": \"user\", \"content\": \"Estoy interesado en conocer los derechos y obligaciones en el ámbito familiar, como el divorcio y la custodia de los hijos.\"},\n",
    "    {\"role\": \"system\", \"name\": \"system\", \"content\": \"Entiendo, en Colombia, el divorcio y la custodia de los hijos son regulados por el Código de Familia. ¿Te gustaría saber más sobre los procedimientos y requisitos para el divorcio?\"},\n",
    "    {\"role\": \"user\", \"name\": \"user\", \"content\": \"Sí, por favor. ¿Cuáles son los pasos que debo seguir para solicitar un divorcio en Colombia?\"},\n",
    "    {\"role\": \"system\", \"name\": \"system\", \"content\": \"Para solicitar un divorcio en Colombia, debes cumplir con ciertos requisitos, como la separación de hecho por al menos un año. Luego, puedes presentar una demanda de divorcio ante un juez de familia. Es importante contar con asesoría legal en este proceso.\"},\n",
    "    # Agrega más mensajes según sea necesario para continuar la conversación.\n",
    "]\n",
    "\n",
    "for model in {\n",
    "        \"gpt-3.5-turbo-0301\",\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4\",\n",
    "        }:\n",
    "    print(model)\n",
    "    # Example token count for the function defined above\n",
    "    print(f\"{num_tokens_from_message(example_messages, model)} prompt tokens counted by num_tokens_from_messages().\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=example_messages,\n",
    "    temperature =0.2,\n",
    "    max_tokens=1,\n",
    ")\n",
    "    # top_p=1,\n",
    "    # frequency_penalty = 0,\n",
    "    # presence_penalty = 0\n",
    "    print(f\"{response['usage']['prompt_tokens']} prompt tokens counted by the OPENAI API. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
